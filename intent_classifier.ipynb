{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_processing import get_datafrom_tokenizer\n",
    "from baseline import BERTClass\n",
    "\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing \n",
    "In this part we load the data and pre-process them (see *data_processing.py*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset silicone (C:/Users/jerem/.cache/huggingface/datasets/silicone/dyda_da/1.0.0/af617406c94e3f78da85f7ea74ebfbd3f297a9665cb54adbae305b03bc4442a5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a5b62c99394ff599b08f5c947706b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"silicone\", \"dyda_da\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Dialogue_Act</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>say , jim , how about going for a few beers af...</td>\n",
       "      <td>directive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you know that is tempting but is really not go...</td>\n",
       "      <td>commissive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what do you mean ? it will help us to relax .</td>\n",
       "      <td>question</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>do you really think so ? i don't . it will jus...</td>\n",
       "      <td>question</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i guess you are right.but what shall we do ? i...</td>\n",
       "      <td>question</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87165</th>\n",
       "      <td>i want a pair of locus .</td>\n",
       "      <td>directive</td>\n",
       "      <td>11117</td>\n",
       "      <td>1</td>\n",
       "      <td>87165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87166</th>\n",
       "      <td>take a look at the ones on display , please .</td>\n",
       "      <td>commissive</td>\n",
       "      <td>11117</td>\n",
       "      <td>0</td>\n",
       "      <td>87166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87167</th>\n",
       "      <td>i need size 41 .</td>\n",
       "      <td>directive</td>\n",
       "      <td>11117</td>\n",
       "      <td>1</td>\n",
       "      <td>87167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87168</th>\n",
       "      <td>could i have the check , please ?</td>\n",
       "      <td>directive</td>\n",
       "      <td>11118</td>\n",
       "      <td>1</td>\n",
       "      <td>87168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87169</th>\n",
       "      <td>okay . i'll just be a minute .</td>\n",
       "      <td>commissive</td>\n",
       "      <td>11118</td>\n",
       "      <td>0</td>\n",
       "      <td>87169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87170 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Utterance Dialogue_Act  \\\n",
       "0      say , jim , how about going for a few beers af...    directive   \n",
       "1      you know that is tempting but is really not go...   commissive   \n",
       "2          what do you mean ? it will help us to relax .     question   \n",
       "3      do you really think so ? i don't . it will jus...     question   \n",
       "4      i guess you are right.but what shall we do ? i...     question   \n",
       "...                                                  ...          ...   \n",
       "87165                           i want a pair of locus .    directive   \n",
       "87166      take a look at the ones on display , please .   commissive   \n",
       "87167                                   i need size 41 .    directive   \n",
       "87168                  could i have the check , please ?    directive   \n",
       "87169                     okay . i'll just be a minute .   commissive   \n",
       "\n",
       "      Dialogue_ID  Label    Idx  \n",
       "0               1      1      0  \n",
       "1               1      0      1  \n",
       "2               1      3      2  \n",
       "3               1      3      3  \n",
       "4               1      3      4  \n",
       "...           ...    ...    ...  \n",
       "87165       11117      1  87165  \n",
       "87166       11117      0  87166  \n",
       "87167       11117      1  87167  \n",
       "87168       11118      1  87168  \n",
       "87169       11118      0  87169  \n",
       "\n",
       "[87170 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset[\"train\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train = pd.DataFrame(dataset[\"train\"])[[\"Utterance\", \"Label\"]].sample(10000, ignore_index=True)\n",
    "small_test = pd.DataFrame(dataset[\"test\"])[[\"Utterance\", \"Label\"]].sample(1000, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>say , jim , how about going for a few beers af...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you know that is tempting but is really not go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what do you mean ? it will help us to relax .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>do you really think so ? i don't . it will jus...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i guess you are right.but what shall we do ? i...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87165</th>\n",
       "      <td>i want a pair of locus .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87166</th>\n",
       "      <td>take a look at the ones on display , please .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87167</th>\n",
       "      <td>i need size 41 .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87168</th>\n",
       "      <td>could i have the check , please ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87169</th>\n",
       "      <td>okay . i'll just be a minute .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87170 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Utterance  Label\n",
       "0      say , jim , how about going for a few beers af...      1\n",
       "1      you know that is tempting but is really not go...      0\n",
       "2          what do you mean ? it will help us to relax .      3\n",
       "3      do you really think so ? i don't . it will jus...      3\n",
       "4      i guess you are right.but what shall we do ? i...      3\n",
       "...                                                  ...    ...\n",
       "87165                           i want a pair of locus .      1\n",
       "87166      take a look at the ones on display , please .      0\n",
       "87167                                   i need size 41 .      1\n",
       "87168                  could i have the check , please ?      1\n",
       "87169                     okay . i'll just be a minute .      0\n",
       "\n",
       "[87170 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_train = pd.DataFrame(dataset['train'])[[\"Utterance\", \"Label\"]]\n",
    "simple_test = pd.DataFrame(dataset['test'])[[\"Utterance\", \"Label\"]]\n",
    "simple_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_datafrom_tokenizer(simple_train, simple_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "In this part we load the custom model BERTClass (see *baseline.py*) and we define two functions: one to train the model and the other to best validate and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = BERTClass()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_loss(model, testloader, criterion, no_training_phase=False):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(testloader, 0):\n",
    "            ids = data['ids'].to(device)\n",
    "            mask = data['mask'].to(device)\n",
    "            token_type_ids = data['token_type_ids'].to(device)\n",
    "            targets = data['targets'].to(device)\n",
    "\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item() * targets.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        if no_training_phase:\n",
    "            print(f\"Test Error: \\n Accuracy: {(100*correct/total):>0.1f}%, Avg loss: {test_loss/total:>8f} \\n\")\n",
    "            return None\n",
    "        else:\n",
    "            return test_loss/total, 1-correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t l3.weight\n",
      "\t l3.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update = model.parameters()\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, test_loader, train_epoch=10):\n",
    "    loss_train = []\n",
    "    train_accuracy = []\n",
    "    loss_test = []\n",
    "    test_accuracy = []\n",
    "\n",
    "    epoch_pbar = tqdm(total=train_epoch, leave=False)\n",
    "    for epoch in range(train_epoch):  \n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            pbar = tqdm(leave=True, total=len(train_loader))\n",
    "            for i, data in enumerate(train_loader, 0):\n",
    "                ids = data['ids'].to(device)\n",
    "                mask = data['mask'].to(device)\n",
    "                token_type_ids = data['token_type_ids'].to(device)\n",
    "                targets = data['targets'].to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(ids, mask, token_type_ids)\n",
    "                # outputs = probs.argmax(1) # to use for accuracy metrics\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "            \n",
    "                optimizer.step()\n",
    "            \n",
    "                train_loss += loss.item() * len(targets)\n",
    "                pbar.set_description(f\"Train Loss : {loss: .4f}\")\n",
    "                pbar.update()\n",
    "\n",
    "            loss, errors = compute_test_loss(model, test_loader, criterion)\n",
    "            loss_test.append(loss)\n",
    "            test_accuracy.append(1-errors)\n",
    "            pbar.set_description(f\"Train Loss : {train_loss/total: .4f} | Test Loss : {loss: .4f} | Train Error : {1 - correct/total: .2%} | Test Error : {errors: .2%}\")\n",
    "            pbar.update()\n",
    "            loss_train.append(train_loss/total)\n",
    "            train_accuracy.append(correct/total)\n",
    "            epoch_pbar.set_description(f\"Epoch : {epoch}/{train_epoch} | Train Loss : {train_loss/total: .4f} | Test Loss : {loss: .4f} | Train Error : {1 - correct/total: .2%} | Test Error : {errors: .2%}\")\n",
    "            epoch_pbar.update() \n",
    "            \n",
    "    return loss_test, test_accuracy, loss_train, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_test, test_accuracy, loss_train, train_accuracy = train(train_loader, test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy and sanity checks of the model\n",
    "Now we load the best one we have trained and checks all metrics about its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = torch.load(\"../baseline_dict2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_old = BERTClass()\n",
    "model_old.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.687908 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "compute_test_loss(model_old.to(device), test_loader, criterion, no_training_phase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "mask = []\n",
    "token_type = []\n",
    "target = []\n",
    "for i, data in enumerate(test_loader):\n",
    "    ids.append(data[\"ids\"])\n",
    "    mask.append(data[\"mask\"])\n",
    "    token_type.append(data[\"token_type_ids\"])\n",
    "    target.append(data[\"targets\"])\n",
    "    if i == 10:\n",
    "        break\n",
    "ids = torch.vstack(ids[:-1])\n",
    "mask = torch.vstack(mask[:-1])\n",
    "token_type = torch.vstack(token_type[:-1])\n",
    "target = torch.hstack(target[:-1])\n",
    "\n",
    "pred = model_old(ids, mask, token_type).max(1)[1].detach().cpu().numpy()\n",
    "report2 = classification_report(target, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.06        32\n",
      "           1       0.56      0.38      0.45        50\n",
      "           2       0.69      0.89      0.78       142\n",
      "           3       0.79      0.83      0.81        96\n",
      "\n",
      "    accuracy                           0.71       320\n",
      "   macro avg       0.76      0.53      0.53       320\n",
      "weighted avg       0.73      0.71      0.67       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e6f3ddecb87735b1ab8fa6a1b52c620169bb3321dea32377e3f33dc82148553"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
